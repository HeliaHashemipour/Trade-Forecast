{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Load your yearly time series data into a Pandas DataFrame\n",
    "data = pd.read_csv('/content/merged_data.csv')\n",
    "# Sort the DataFrame in ascending order in-place\n",
    "data.sort_values(by='Year', ascending=True, inplace=True)\n",
    "data= data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for LSTM input with a custom window size\n",
    "\n",
    "def create_sequences(data_column, window_length):\n",
    "    X_sequences = []\n",
    "    y_sequences = []\n",
    "    column_data = data_column.to_numpy()\n",
    "\n",
    "    for i in range(len(column_data) - window_length):\n",
    "        X_sequence = column_data[i:i + window_length]\n",
    "        y_sequence = column_data[i + window_length]\n",
    "        X_sequences.append(X_sequence)\n",
    "        y_sequences.append(y_sequence)\n",
    "        # print(y_sequences)\n",
    "\n",
    "    return np.array(X_sequences), np.array(y_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size for the LSTM model\n",
    "window_length = 5\n",
    "\n",
    "# Create input sequences and labels for each column\n",
    "X_sequences_dict = {}\n",
    "y_sequences_dict = {}\n",
    "\n",
    "\n",
    "for column in data.columns[1:]:\n",
    "    X_column, y_column = create_sequences(data[column], window_length)\n",
    "    X_sequences_dict[column] = X_column\n",
    "    y_sequences_dict[column] = y_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a 2-dimensional NumPy array\n",
    "y = np.array(list(y_sequences_dict.values()))\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "y_normalized = scaler.fit_transform(y)\n",
    "# # Use the flatten method to create a 1-dimensional array\n",
    "y_normalized = y_normalized.flatten()\n",
    "\n",
    "# Initialize an empty list to store the flattened arrays\n",
    "flattened_arrays = []\n",
    "\n",
    "# Loop through the dictionary and flatten each array based on its key\n",
    "for key, array in X_sequences_dict.items():\n",
    "\n",
    "    flattened_array = array.flatten()\n",
    "    flattened_arrays.append(flattened_array)\n",
    "    # print(flattened_array)\n",
    "\n",
    "\n",
    "# # Convert the list of flattened arrays to a 2-dimensional NumPy array\n",
    "X = np.array(list(X_sequences_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to have only one sequence per sample\n",
    "X = np.reshape(X, (-1, 5))\n",
    "X_normalized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_normalized = scaler.fit_transform(X)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_normalized, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = Sequential()\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=1000)\n",
    "mlp_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for Canada\n",
    "X_canada, y_canada = create_sequences(data['canada_gdp_data'], window_length)\n",
    "# X_canada = scaler.transform(X_canada)  # Normalize the input data\n",
    "X_canada = np.array(X_canada)\n",
    "X_canada = np.reshape(X_canada, (-1, 5))  # Reshape the data to match MLP input\n",
    "\n",
    "y_canada_predicted = mlp_regressor.predict(X_canada)  # Predict using MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already performed the steps for predictions and have y_canada and y_canada_predicted available\n",
    "\n",
    "# Create a range of indices for the plot\n",
    "indices = np.arange(len(y_canada))\n",
    "\n",
    "# Plot the original and predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, y_canada, label='Original Canada Values', marker='o')\n",
    "plt.plot(indices, y_canada_predicted, label='Predicted Canada Values', marker='x')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Predicted Canada Values')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
