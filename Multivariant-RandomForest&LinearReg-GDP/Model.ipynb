{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where the CSV files are saved\n",
    "csv_files_directory = './'  # Change this to the directory where the CSV files are saved\n",
    "\n",
    "# Get a list of all CSV files that end with '_pop_data.csv'\n",
    "csv_files = [file for file in os.listdir(csv_files_directory) if file.endswith('_gdp_data.csv')]\n",
    "\n",
    "# Initialize a list to store DataFrames for each country\n",
    "country_dataframes = []\n",
    "\n",
    "# Loop through the CSV files and read them into DataFrames\n",
    "for csv_file in csv_files:\n",
    "    country_df = pd.read_csv(csv_file)\n",
    "    # print(os.path.splitext(csv_file)[0])\n",
    "    # country_df = country_df.sort_values(by='Year', ascending=True)\n",
    "    country_dataframes.append(country_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files(directory_path):\n",
    "    # Initialize the merged DataFrame with None\n",
    "    merged_df = None\n",
    "\n",
    "    # Iterate through each file in the directory and read it into a DataFrame\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\"_modified.csv\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(file_path)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Perform the merge\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = pd.merge(merged_df, df, on='Year', how='inner')\n",
    "\n",
    "    # Set the 'Year' column as the index\n",
    "    if merged_df is not None:\n",
    "        merged_df.set_index('Year', inplace=True)\n",
    "\n",
    "        # Sort the DataFrame in ascending order based on the index 'Year'\n",
    "        merged_df.sort_index(inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to the directory containing the CSV files\n",
    "    directory_path = \"/Users/heliaa/University/Code\"\n",
    "\n",
    "    # Merge all the CSV files into a single DataFrame and sort it\n",
    "    merged_df = merge_csv_files(directory_path)\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    if merged_df is not None:\n",
    "        merged_df.to_csv(\"merged_data.csv\")\n",
    "    else:\n",
    "        print(\"No CSV files found for merging.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_data.csv',index_col='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the entire dataset\n",
    "global_correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_pairs = correlation_matrix.unstack().sort_values(ascending=False)\n",
    "top_5_corr_columns = correlation_pairs[correlation_pairs != 1.0][:5]\n",
    "\n",
    "print(\"Top 5 correlated column pairs:\")\n",
    "print(top_5_corr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We use 'reset_index' to convert the multi-index Series back to a DataFrame.\n",
    "top_5_corr_matrix = global_correlation_matrix.loc[top_5_corr_columns.index.get_level_values(0),\n",
    "                                                 top_5_corr_columns.index.get_level_values(1)]\n",
    "\n",
    "\n",
    "# Step 6: Plot the correlation heatmap using seaborn\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(top_5_corr_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap of Top 5 Columns')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Get the names of the top 5 correlated columns\n",
    "top_5_corr_column_names = top_5_corr_columns.index.get_level_values(0).unique()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, column in enumerate(top_5_corr_column_names, 1):\n",
    "    plt.subplot(5, 1, i)\n",
    "    plt.plot(df.index, df[column])\n",
    "    plt.ylabel(column)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.suptitle('Time Series Plots of Top 5 Correlated Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original DataFrame to include only data from the top 5 correlated countries\n",
    "top_5_corr_data = df[top_5_corr_column_names]\n",
    "\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "top_5_corr_data.to_csv('top_5_correlated_countries_with_year.csv')\n",
    "\n",
    "data = pd.read_csv('top_5_correlated_countries_with_year.csv')\n",
    "\n",
    "X = data.drop(columns=['Year','thailand'])\n",
    "y  = data['thailand']\n",
    "\n",
    "\n",
    "year = data['Year'].astype(str)\n",
    "data['Year'] = pd.to_datetime(year)\n",
    "    # Set 'date' column as the index\n",
    "data.set_index('Year', inplace=True)\n",
    "\n",
    "\n",
    "data['Prediction']=data[['thailand']].shift(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.drop(['Prediction'],1))\n",
    "X=X[:-6]\n",
    "y = np.array(data['Prediction'])\n",
    "y=y[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and fit the LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the coefficients (slopes) and the intercept\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already imported the necessary libraries, including numpy and the model.\n",
    "forecast=np.array(data.drop(['Prediction'],1))[-6:]\n",
    "\n",
    "pred=model.predict(forecast)\n",
    "\n",
    "# Round the prediction values to integers (without decimal places)\n",
    "pred = pred.astype(int)\n",
    "\n",
    "# Creating a DataFrame for the forecast values with corresponding dates\n",
    "forecast_dates = pd.date_range(start=data.index[-1], periods=len(pred)+1, freq='A')[-len(pred):]\n",
    "forecast_df = pd.DataFrame({'thailand': pred}, index=forecast_dates)\n",
    "\n",
    "# Merging the original DataFrame and the forecast DataFrame\n",
    "merged_df = pd.concat([data, forecast_df])\n",
    "\n",
    "merged_df.to_csv(f'final_modified1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute average correlation for each column\n",
    "average_correlations = correlation_matrix.abs().mean()\n",
    "\n",
    "# Get the top 5 columns with the highest average correlation\n",
    "next_5_corr_columns = average_correlations.nlargest(5)\n",
    "\n",
    "print(\"Next 5 correlated columns:\")\n",
    "print(next_5_corr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Get the names of the top 5 correlated columns\n",
    "top_5_corr_column_names = next_5_corr_columns.index.get_level_values(0).unique()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, column in enumerate(top_5_corr_column_names, 1):\n",
    "    plt.subplot(5, 1, i)\n",
    "    plt.plot(df.index, df[column])\n",
    "    plt.ylabel(column)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.suptitle('Time Series Plots of Top 5 Correlated Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original DataFrame to include only data from the top 5 correlated countries\n",
    "top_5_corr_data = df[top_5_corr_column_names]\n",
    "\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "top_5_corr_data.to_csv('top_5_correlated_countries_with_year.csv')\n",
    "\n",
    "data = pd.read_csv('top_5_correlated_countries_with_year.csv')\n",
    "\n",
    "X = data.drop(columns=['Year','thailand'])\n",
    "y  = data['thailand']\n",
    "\n",
    "\n",
    "year = data['Year'].astype(str)\n",
    "data['Year'] = pd.to_datetime(year)\n",
    "    # Set 'date' column as the index\n",
    "data.set_index('Year', inplace=True)\n",
    "\n",
    "\n",
    "data['Prediction']=data[['thailand']].shift(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.drop(['Prediction'],1))\n",
    "X=X[:-6]\n",
    "y = np.array(data['Prediction'])\n",
    "y=y[:-6]\n",
    "\n",
    "\n",
    "# Initialize a list to store the MAE and MSE for each country\n",
    "mae_results_rf = []\n",
    "mse_results_rf = []\n",
    "mae_results_lr = []\n",
    "mse_results_lr = []\n",
    "\n",
    "\n",
    "# Step 3: Initialize the StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Step 4: Standardize each row in the DataFrame\n",
    "standardized_data = []\n",
    "for _, row in X.iterrows():\n",
    "    scaled_row = scaler.fit_transform(row.values.reshape(1, -1))\n",
    "    standardized_data.append(scaled_row)\n",
    "\n",
    "\n",
    "\n",
    "# Create and fit the LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# Assuming you have already imported the necessary libraries, including numpy and the model.\n",
    "forecast=np.array(data.drop(['Prediction'],1))[-6:]\n",
    "\n",
    "pred=model.predict(forecast)\n",
    "\n",
    "# Round the prediction values to integers (without decimal places)\n",
    "pred = pred.astype(int)\n",
    "\n",
    "# Creating a DataFrame for the forecast values with corresponding dates\n",
    "forecast_dates = pd.date_range(start=data.index[-1], periods=len(pred)+1, freq='A')[-len(pred):]\n",
    "forecast_df = pd.DataFrame({'thailand': pred}, index=forecast_dates)\n",
    "\n",
    "# Merging the original DataFrame and the forecast DataFrame\n",
    "merged_df = pd.concat([data, forecast_df])\n",
    "\n",
    "merged_df.to_csv(f'final_modified2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#load the data\n",
    "data = pd.read_csv('canada_gdp_data.csv')\n",
    "\n",
    "# Sort the DataFrame in ascending order\n",
    "data = data.sort_values(by=data.columns.tolist())\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#divide into train and validation set\n",
    "train = data[:int(0.7*(len(data)))]\n",
    "valid = data[int(0.7*(len(data))):]\n",
    "\n",
    "#preprocessing (since arima takes univariate series as input)\n",
    "train.drop('Year',axis=1,inplace=True)\n",
    "valid.drop('Year',axis=1,inplace=True)\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the data\n",
    "train['GDP'].plot()\n",
    "valid['GDP'].plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
