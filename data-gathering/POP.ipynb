{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting version of chromedriver 115. Retrying with chromedriver 114 (attempt 1/5)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Install Chrome driver\n",
    "ChromeDriverManager().install()\n",
    "ser = Service()\n",
    "driver = webdriver.Chrome(service=ser)\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.macrotrends.net/countries/USA/united-states/population\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "header = [\"Year\", \"Population\"]\n",
    "\n",
    "# Loop through the rows and extract the data\n",
    "for row in rows[2:]:  # Start from the third row to skip the header rows\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    year = cells[0].text\n",
    "    pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")  # Convert to numeric format\n",
    "    data.append([year, pop])\n",
    "\n",
    "# Create a DataFrame from the data for Canada\n",
    "df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "# Save the DataFrame to a CSV file for Canada\n",
    "df.to_csv(\"united-states.csv\", index=False)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[9]')\n",
    "# Get the links for other countries\n",
    "country_links = table.find_elements(By.TAG_NAME, \"a\")\n",
    "country_list_href = [a.get_attribute('href') for a in country_links]\n",
    "\n",
    "# Loop through the links and save data for each country\n",
    "for link in country_list_href:\n",
    "        # Check if the CSV file for the country already exists\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    driver.get(link) # Click on the link to navigate to the country's page\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    # Find the table containing the data for the country\n",
    "    country_table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "    country_rows = country_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    country_data = []\n",
    "    # Loop through the rows and extract the data for the country\n",
    "    for row in country_rows[2:]:  # Start from the third row to skip the header rows\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        year = cells[0].text\n",
    "        pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")   # Convert to numeric format\n",
    "        country_data.append([year, pop])\n",
    "    # Create a DataFrame from the data for the country\n",
    "    country_df = pd.DataFrame(country_data, columns=header)\n",
    "    # Extract the country name from the URL and use it as the CSV file name\n",
    "    country_name = link.split(\"/\")[-2]\n",
    "    \n",
    "    if os.path.exists(f\"{country_name}.csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        # Save the DataFrame to a new CSV file for the current country\n",
    "        country_df.to_csv(f\"{country_name}.csv\", index=False)\n",
    "    \n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Install Chrome driver\n",
    "ChromeDriverManager().install()\n",
    "ser = Service()\n",
    "driver = webdriver.Chrome(service=ser)\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.macrotrends.net/countries/CHN/china/population\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "header = [\"Year\", \"Population\"]\n",
    "\n",
    "# Loop through the rows and extract the data\n",
    "for row in rows[2:]:  # Start from the third row to skip the header rows\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    year = cells[0].text\n",
    "    pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")  # Convert to numeric format\n",
    "    data.append([year, pop])\n",
    "\n",
    "# Create a DataFrame from the data for Canada\n",
    "df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "# Save the DataFrame to a CSV file for Canada\n",
    "df.to_csv(\"china.csv\", index=False)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[9]')\n",
    "# Get the links for other countries\n",
    "country_links = table.find_elements(By.TAG_NAME, \"a\")\n",
    "country_list_href = [a.get_attribute('href') for a in country_links]\n",
    "\n",
    "# Loop through the links and save data for each country\n",
    "for link in country_list_href:\n",
    "        # Check if the CSV file for the country already exists\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    driver.get(link) # Click on the link to navigate to the country's page\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    # Find the table containing the data for the country\n",
    "    country_table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "    country_rows = country_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    country_data = []\n",
    "    # Loop through the rows and extract the data for the country\n",
    "    for row in country_rows[2:]:  # Start from the third row to skip the header rows\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        year = cells[0].text\n",
    "        pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")   # Convert to numeric format\n",
    "        country_data.append([year, pop])\n",
    "    # Create a DataFrame from the data for the country\n",
    "    country_df = pd.DataFrame(country_data, columns=header)\n",
    "    # Extract the country name from the URL and use it as the CSV file name\n",
    "    country_name = link.split(\"/\")[-2]\n",
    "    \n",
    "    if os.path.exists(f\"{country_name}.csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        # Save the DataFrame to a new CSV file for the current country\n",
    "        country_df.to_csv(f\"{country_name}.csv\", index=False)\n",
    "    \n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Install Chrome driver\n",
    "ChromeDriverManager().install()\n",
    "ser = Service()\n",
    "driver = webdriver.Chrome(service=ser)\n",
    "\n",
    "# Open the website\n",
    "driver.get(\"https://www.macrotrends.net/countries/ETH/ethiopia/population\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "\n",
    "# Extract the rows from the table\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "header = [\"Year\", \"Population\"]\n",
    "\n",
    "# Loop through the rows and extract the data\n",
    "for row in rows[2:]:  # Start from the third row to skip the header rows\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    year = cells[0].text\n",
    "    pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")  # Convert to numeric format\n",
    "    data.append([year, pop])\n",
    "\n",
    "# Create a DataFrame from the data for Canada\n",
    "df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "# Save the DataFrame to a CSV file for Canada\n",
    "df.to_csv(\"ethiopia_pop_data.csv\", index=False)\n",
    "\n",
    "# Find the table containing the data\n",
    "table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[9]')\n",
    "# Get the links for other countries\n",
    "country_links = table.find_elements(By.TAG_NAME, \"a\")\n",
    "country_list_href = [a.get_attribute('href') for a in country_links]\n",
    "\n",
    "# Loop through the links and save data for each country\n",
    "for link in country_list_href:\n",
    "        # Check if the CSV file for the country already exists\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    driver.get(link) # Click on the link to navigate to the country's page\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    # Find the table containing the data for the country\n",
    "    country_table = driver.find_element(By.XPATH, '//*[@id=\"main_content\"]/div[11]')\n",
    "    country_rows = country_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "    country_data = []\n",
    "    # Loop through the rows and extract the data for the country\n",
    "    for row in country_rows[2:]:  # Start from the third row to skip the header rows\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        year = cells[0].text\n",
    "        pop = cells[1].text.replace(\",\", \"\").replace(\",\", \"\")   # Convert to numeric format\n",
    "        country_data.append([year, pop])\n",
    "    # Create a DataFrame from the data for the country\n",
    "    country_df = pd.DataFrame(country_data, columns=header)\n",
    "    # Extract the country name from the URL and use it as the CSV file name\n",
    "    country_name = link.split(\"/\")[-2]\n",
    "    \n",
    "    if os.path.exists(f\"{country_name}_pop_data.csv\"):\n",
    "        continue\n",
    "    else:\n",
    "        # Save the DataFrame to a new CSV file for the current country\n",
    "        country_df.to_csv(f\"{country_name}_pop_data.csv\", index=False)\n",
    "    \n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
